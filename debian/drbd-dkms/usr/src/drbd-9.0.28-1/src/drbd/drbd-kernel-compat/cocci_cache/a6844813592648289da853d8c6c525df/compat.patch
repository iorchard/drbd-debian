--- ./drbd_int.h
+++ /tmp/cocci-output-3683926-b9e696-drbd_int.h
@@ -1853,7 +1853,7 @@ extern void do_submit(struct work_struct
 #define __drbd_make_request(d,b,k,j) __drbd_make_request(d,b,j)
 #endif
 extern void __drbd_make_request(struct drbd_device *, struct bio *, ktime_t, unsigned long);
-extern blk_qc_t drbd_submit_bio(struct bio *bio);
+extern blk_qc_t drbd_make_request(struct request_queue *q, struct bio *bio);
 
 /* drbd_nl.c */
 enum suspend_scope {
@@ -2072,7 +2072,7 @@ static inline void drbd_submit_bio_noacc
 		bio->bi_status = BLK_STS_IOERR;
 		bio_endio(bio);
 	} else {
-		submit_bio_noacct(bio);
+		generic_make_request(bio);
 	}
 }
 
@@ -2208,7 +2208,7 @@ static inline void __drbd_chk_io_error_(
 			}
 			break;
 		}
-		fallthrough;	/* for DRBD_META_IO_ERROR or DRBD_FORCE_DETACH */
+		;/* fallthrough */	/* for DRBD_META_IO_ERROR or DRBD_FORCE_DETACH */
 	case EP_DETACH:
 	case EP_CALL_HELPER:
 		/* Remember whether we saw a READ or WRITE error.
--- drbd-headers/linux/genl_magic_struct.h
+++ /tmp/cocci-output-3683926-c86571-genl_magic_struct.h
@@ -107,7 +107,7 @@ static inline int nla_put_u64_0pad(struc
 			nla_get_u64, nla_put_u64_0pad, false)
 #define __str_field(attr_nr, attr_flag, name, maxlen) \
 	__array(attr_nr, attr_flag, name, NLA_NUL_STRING, char, maxlen, \
-			nla_strscpy, nla_put, false)
+			nla_strlcpy, nla_put, false)
 #define __bin_field(attr_nr, attr_flag, name, maxlen) \
 	__array(attr_nr, attr_flag, name, NLA_BINARY, char, maxlen, \
 			nla_memcpy, nla_put, false)
--- drbd_state.c
+++ /tmp/cocci-output-3683926-449b49-drbd_state.c
@@ -146,7 +146,7 @@ static bool may_be_up_to_date(struct drb
 		case D_DISKLESS:
 			if (!(peer_md->flags & MDF_PEER_DEVICE_SEEN))
 				continue;
-			fallthrough;
+			;/* fallthrough */
 		case D_ATTACHING:
 		case D_DETACHING:
 		case D_FAILED:
--- drbd_receiver.c
+++ /tmp/cocci-output-3683926-d04f40-drbd_receiver.c
@@ -32,7 +32,6 @@
 #include <linux/random.h>
 #include <net/ipv6.h>
 #include <linux/scatterlist.h>
-#include <linux/part_stat.h>
 
 #include "drbd_int.h"
 #include "drbd_protocol.h"
@@ -1600,7 +1599,7 @@ static bool can_do_reliable_discards(str
 	if (!blk_queue_discard(q))
 		return false;
 
-	if (queue_discard_zeroes_data(q))
+	if (0/* queue_discard_zeroes_data(q) */)
 		return true;
 
 	rcu_read_lock();
@@ -1875,7 +1874,7 @@ int w_e_reissue(struct drbd_work *w, int
 		drbd_queue_work(&peer_device->connection->sender_work,
 				&peer_req->w);
 		/* retry later */
-		fallthrough;
+		;/* fallthrough */
 	case 0:
 		/* keep worker happy and connection up */
 		return 0;
@@ -3388,7 +3387,7 @@ static int receive_DataRequest(struct dr
 			/* case P_DATA_REQUEST: see above, not based on protocol version */
 			case P_OV_REQUEST:
 				verify_skipped_block(peer_device, sector, size);
-				fallthrough;
+				;/* fallthrough */
 			case P_RS_DATA_REQUEST:
 			case P_RS_THIN_REQ:
 			case P_CSUM_RS_REQUEST:
@@ -3417,7 +3416,7 @@ static int receive_DataRequest(struct dr
 		   then we would do something smarter here than reading
 		   the block... */
 		peer_req->flags |= EE_RS_THIN_REQ;
-		fallthrough;
+		;/* fallthrough */
 	case P_RS_DATA_REQUEST:
 		peer_req->w.cb = w_e_end_rsdata_req;
 		break;
@@ -3599,7 +3598,7 @@ static enum sync_strategy drbd_asb_recov
 			rv = SYNC_SOURCE_USE_BITMAP;
 			break;
 		}
-		fallthrough;	/* to one of the other strategies */
+		;/* fallthrough */	/* to one of the other strategies */
 	case ASB_DISCARD_OLDER_PRI:
 		if (self == 0 && peer == 1) {
 			rv = SYNC_SOURCE_USE_BITMAP;
@@ -3611,7 +3610,7 @@ static enum sync_strategy drbd_asb_recov
 		}
 		drbd_warn(peer_device, "Discard younger/older primary did not find a decision\n"
 			  "Using discard-least-changes instead\n");
-		fallthrough;
+		;/* fallthrough */
 	case ASB_DISCARD_ZERO_CHG:
 		if (ch_peer == 0 && ch_self == 0) {
 			rv = test_bit(RESOLVE_CONFLICTS, &peer_device->connection->transport.flags)
@@ -3623,7 +3622,7 @@ static enum sync_strategy drbd_asb_recov
 		}
 		if (after_sb_0p == ASB_DISCARD_ZERO_CHG)
 			break;
-		fallthrough;
+		;/* fallthrough */
 	case ASB_DISCARD_LEAST_CHG:
 		if	(ch_self < ch_peer)
 			rv = SYNC_TARGET_USE_BITMAP;
@@ -4517,7 +4516,7 @@ static enum drbd_repl_state drbd_sync_ha
 		switch (rr_conflict) {
 		case ASB_CALL_HELPER:
 			drbd_maybe_khelper(device, connection, "pri-lost");
-			fallthrough;
+			;/* fallthrough */
 		case ASB_DISCONNECT:
 		case ASB_RETRY_CONNECT:
 			drbd_err(device, "I shall become SyncTarget, but I am primary!\n");
@@ -9089,7 +9088,7 @@ static int got_NegRSDReply(struct drbd_c
 			break;
 		case P_RS_CANCEL_AHEAD:
 			set_bit(SYNC_TARGET_TO_BEHIND, &peer_device->flags);
-			fallthrough;
+			;/* fallthrough */
 		case P_RS_CANCEL:
 			if (peer_device->repl_state[NOW] == L_VERIFY_S) {
 				verify_skipped_block(peer_device, sector, size);
@@ -9446,7 +9445,15 @@ int drbd_ack_receiver(struct drbd_thread
 	struct drbd_transport *transport = &connection->transport;
 	struct drbd_transport_ops *tr_ops = transport->ops;
 
-	sched_set_fifo_low(current);
+	struct sched_param param = {
+		.sched_priority = 2
+		};
+	int ____rv0;
+	____rv0 = sched_setscheduler(current, SCHED_RR, &param);
+	if (____rv0 < 0)
+		drbd_err(connection,
+			 "drbd_ack_receiver: ERROR set priority, ret=%d\n",
+			 ____rv0);
 
 	while (get_t_state(thi) == RUNNING) {
 		drbd_thread_current_set_cpu(thi);
--- drbd_main.c
+++ /tmp/cocci-output-3683926-e2422a-drbd_main.c
@@ -70,6 +70,7 @@ MODULE_PARM_DESC(minor_count, "Approxima
 MODULE_ALIAS_BLOCKDEV_MAJOR(DRBD_MAJOR);
 
 #include <linux/moduleparam.h>
+#include <linux/vermagic.h>
 
 #ifdef CONFIG_DRBD_FAULT_INJECTION
 int drbd_enable_faults;
@@ -147,7 +148,6 @@ struct bio_set drbd_io_bio_set;
 
 static const struct block_device_operations drbd_ops = {
 	.owner		= THIS_MODULE,
-	.submit_bio	= drbd_submit_bio,
 	.open		= drbd_open,
 	.release	= drbd_release,
 };
@@ -578,8 +578,8 @@ static int drbd_thread_setup(void *arg)
 	unsigned long flags;
 	int retval;
 
-	allow_kernel_signal(DRBD_SIGKILL);
-	allow_kernel_signal(SIGXCPU);
+	allow_signal(DRBD_SIGKILL);
+	allow_signal(SIGXCPU);
 
 	if (connection)
 		kref_get(&connection->kref);
@@ -695,7 +695,7 @@ int drbd_thread_start(struct drbd_thread
 		else
 			drbd_info(resource, "Restarting %s thread (from %s [%d])\n",
 					thi->name, current->comm, current->pid);
-		fallthrough;
+		;/* fallthrough */
 	case RUNNING:
 	case RESTARTING:
 	default:
@@ -1581,7 +1581,7 @@ static void assign_p_sizes_qlim(struct d
 		p->qlim->io_min = cpu_to_be32(queue_io_min(q));
 		p->qlim->io_opt = cpu_to_be32(queue_io_opt(q));
 		p->qlim->discard_enabled = blk_queue_discard(q);
-		p->qlim->discard_zeroes_data = queue_discard_zeroes_data(q);
+		p->qlim->discard_zeroes_data = 0/* queue_discard_zeroes_data(q) */;
 		p->qlim->write_same_capable = !!q->limits.max_write_same_sectors;
 	} else {
 		q = device->rq_queue;
@@ -2202,7 +2202,7 @@ static int _drbd_send_zc_bio(struct drbd
 		bio_for_each_segment(bvec, bio, iter) {
 			struct page *page = bvec.bv_page;
 
-			if (!sendpage_ok(page)) {
+			if ((PageSlab(page) || page_count(page) < 1)) {
 				no_zc = true;
 				break;
 			}
@@ -3102,6 +3102,61 @@ static void drbd_cleanup(void)
 
 	pr_info("module cleanup done.\n");
 }
+/**
+  * drbd_congested() - Callback for the flusher thread
+  * @congested_data:	User data
+  * @bdi_bits:		Bits the BDI flusher thread is currently interested in
+  *
+  * Returns 1<<WB_async_congested and/or 1<<WB_sync_congested if we are congested.
+  */
+static int drbd_congested(void *congested_data, int bdi_bits){
+	struct drbd_device *device = congested_data;
+	struct request_queue *q;
+	int r = 0;
+
+	if (!may_inc_ap_bio(device)) {
+		/* DRBD has frozen IO */
+		r = bdi_bits;
+		goto out;
+	}
+
+	if (test_bit(CALLBACK_PENDING, &device->resource->flags)) {
+		r |= (1 << WB_async_congested);
+		/* Without good local data, we would need to read from remote,
+ 		 * and that would need the worker thread as well, which is
+ 		 * currently blocked waiting for that usermode helper to
+ 		 * finish.
+ 		 */
+		if (!get_ldev_if_state(device, D_UP_TO_DATE))
+			r |= (1 << WB_sync_congested);
+		else
+			put_ldev(device);
+		r &= bdi_bits;
+		goto out;
+	}
+
+	if (get_ldev(device)) {
+		q = bdev_get_queue(device->ldev->backing_bdev);
+		r = bdi_congested(q->backing_dev_info, bdi_bits);
+		put_ldev(device);
+	}
+
+	if (bdi_bits & (1 << WB_async_congested)) {
+		struct drbd_peer_device *peer_device;
+
+		rcu_read_lock();
+		for_each_peer_device_rcu (peer_device, device) {
+			if (test_bit(NET_CONGESTED, &peer_device->connection->transport.flags)) {
+				r |= (1 << WB_async_congested);
+				break;
+			}
+		}
+		rcu_read_unlock();
+	}
+
+out:
+	return r;
+}
 
 static void drbd_init_workqueue(struct drbd_work_queue* wq)
 {
@@ -3671,7 +3726,7 @@ enum drbd_ret_code drbd_create_device(st
 
 	init_rwsem(&device->uuid_sem);
 
-	q = blk_alloc_queue(NUMA_NO_NODE);
+	q = blk_alloc_queue(GFP_KERNEL);
 	if (!q)
 		goto out_no_q;
 	device->rq_queue = q;
@@ -3689,7 +3744,10 @@ enum drbd_ret_code drbd_create_device(st
 	sprintf(disk->disk_name, "drbd%d", minor);
 	disk->private_data = device;
 
-	blk_queue_flag_set(QUEUE_FLAG_STABLE_WRITES, q);
+	q->backing_dev_info->capabilities |= BDI_CAP_STABLE_WRITES;
+	blk_queue_make_request(q, drbd_make_request);
+	q->backing_dev_info->congested_fn = drbd_congested;
+	q->backing_dev_info->congested_data = device;
 	blk_queue_write_cache(q, true, true);
 
 	device->md_io.page = alloc_page(GFP_KERNEL);
@@ -3941,9 +3999,49 @@ void drbd_reclaim_connection(struct rcu_
 	kref_put(&connection->kref, drbd_destroy_connection);
 }
 
+static int __init double_check_for_kabi_breakage(void)
+{
+#if defined(RHEL_RELEASE_CODE) && ((RHEL_RELEASE_CODE & 0xff00) == 0x700)
+	/* RHEL 7.5 chose to change sizeof(struct nla_policy), and to
+	 * lie about that, which makes the module version magic believe
+	 * it was compatible, while it is not.  To avoid "surprises" in
+	 * nla_parse() later, we ask the running kernel about its
+	 * opinion about the nla_policy_len() of this dummy nla_policy,
+	 * and if it does not agree, we fail on module load already. */
+	static struct nla_policy dummy[] = {
+		[0] = {
+			.type = NLA_UNSPEC,
+			.len = 8,
+		},
+		[1] = {
+			.type = NLA_UNSPEC,
+			.len = 80,
+		},
+		[2] = {
+			.type = NLA_UNSPEC,
+			.len = 800,
+		},
+		[9] = {
+			.type = NLA_UNSPEC,
+		},
+	};
+	int len = nla_policy_len(dummy, 3);
+	if (len != 900) {
+		pr_notice("kernel disagrees about the layout of struct nla_policy (%d)\n",
+			  len);
+		pr_err("kABI breakage detected! module compiled for: %s\n",
+		       UTS_RELEASE);
+		return -EINVAL;
+	}
+#endif
+	return 0;
+}
+
 static int __init drbd_init(void)
 {
 	int err;
+	if (double_check_for_kabi_breakage())
+		return -EINVAL;
 
 	initialize_kref_debugging();
 
--- drbd_nla.c
+++ /tmp/cocci-output-3683926-51b41e-drbd_nla.c
@@ -35,8 +35,7 @@ int drbd_nla_parse_nested(struct nlattr
 
 	err = drbd_nla_check_mandatory(maxtype, nla);
 	if (!err)
-		err = nla_parse_nested_deprecated(tb, maxtype, nla, policy,
-						  NULL);
+		err = nla_parse_nested(tb, maxtype, nla, policy, NULL);
 
 	return err;
 }
--- drbd_req.c
+++ /tmp/cocci-output-3683926-315cec-drbd_req.c
@@ -416,7 +416,9 @@ void drbd_req_complete(struct drbd_reque
 		start_new_tl_epoch(device->resource);
 
 	/* Update disk stats */
-	bio_end_io_acct(req->master_bio, req->start_jif);
+	generic_end_io_acct(req->device->rq_queue,
+			    bio_data_dir(req->master_bio),
+			    &req->device->vdisk->part0, req->start_jif);
 
 	/* If READ failed,
 	 * have it be pushed back to the retry work queue,
@@ -849,7 +851,7 @@ void __req_mod(struct drbd_request *req,
 		drbd_set_all_out_of_sync(device, req->i.sector, req->i.size);
 		drbd_report_io_error(device, req);
 		__drbd_chk_io_error(device, DRBD_READ_ERROR);
-		fallthrough;
+		;/* fallthrough */
 	case READ_AHEAD_COMPLETED_WITH_ERROR:
 		/* it is legal to fail read-ahead, no __drbd_chk_io_error in that case. */
 		mod_rq_state(req, m, peer_device, RQ_LOCAL_PENDING, RQ_LOCAL_COMPLETED);
@@ -1059,7 +1061,7 @@ void __req_mod(struct drbd_request *req,
 					RQ_NET_QUEUED|RQ_NET_PENDING);
 			break;
 		}
-		fallthrough;	/* to BARRIER_ACKED */
+		;/* fallthrough */	/* to BARRIER_ACKED */
 	case BARRIER_ACKED:
 		/* barrier ack for READ requests does not make sense */
 		if (!(req->local_rq_state & RQ_WRITE))
@@ -1481,7 +1483,7 @@ drbd_submit_req_private_bio(struct drbd_
 		} else if (bio_op(bio) == REQ_OP_DISCARD) {
 			drbd_process_discard_or_zeroes_req(req, EE_TRIM);
 		} else {
-			submit_bio_noacct(bio);
+			generic_make_request(bio);
 		}
 		put_ldev(device);
 	} else {
@@ -1552,7 +1554,10 @@ drbd_request_prepare(struct drbd_device
 	}
 
 	/* Update disk stats */
-	req->start_jif = bio_start_io_acct(req->master_bio);
+	req->start_jif = start_jif;
+	generic_start_io_acct(req->device->rq_queue,
+			      bio_data_dir(req->master_bio), req->i.size >> 9,
+			      &req->device->vdisk->part0);
 
 	if (get_ldev(device))
 		req_make_private_bio(req, bio);
@@ -2190,9 +2195,8 @@ static bool drbd_fail_request_early(stru
 	return false;
 }
 
-blk_qc_t drbd_submit_bio(struct bio *bio)
+blk_qc_t drbd_make_request(struct request_queue *q, struct bio *bio)
 {
-	struct request_queue *q = bio->bi_disk->queue;
 	struct drbd_device *device = (struct drbd_device *) q->queuedata;
 #ifdef CONFIG_DRBD_TIMING_STATS
 	ktime_t start_kt;
@@ -2205,7 +2209,7 @@ blk_qc_t drbd_submit_bio(struct bio *bio
 		return BLK_QC_T_NONE;
 	}
 
-	blk_queue_split(&bio);
+	blk_queue_split(bio->bi_disk->queue, &bio);
 
 	if (device->cached_err_io) {
 		bio->bi_status = BLK_STS_IOERR;
--- drbd_nl.c
+++ /tmp/cocci-output-3683926-cec7c9-drbd_nl.c
@@ -114,7 +114,7 @@ static int drbd_msg_put_info(struct sk_b
 	if (!info || !info[0])
 		return 0;
 
-	nla = nla_nest_start_noflag(skb, DRBD_NLA_CFG_REPLY);
+	nla = nla_nest_start(skb, DRBD_NLA_CFG_REPLY);
 	if (!nla)
 		return err;
 
@@ -141,7 +141,7 @@ static int drbd_msg_sprintf_info(struct
 	int aligned_len;
 	char *msg_buf;
 
-	nla = nla_nest_start_noflag(skb, DRBD_NLA_CFG_REPLY);
+	nla = nla_nest_start(skb, DRBD_NLA_CFG_REPLY);
 	if (!nla)
 		return err;
 
@@ -1531,7 +1531,7 @@ void drbd_set_my_capacity(struct drbd_de
 	char ppb[10];
 
 	set_capacity(device->vdisk, size);
-	revalidate_disk_size(device->vdisk, false);
+	revalidate_disk(device->vdisk);
 
 	drbd_info(device, "size = %s (%llu KB)\n",
 		ppsize(ppb, size>>1), (unsigned long long)size>>1);
@@ -1978,7 +1978,7 @@ static void decide_on_discard_support(st
 	 */
 	bool can_do = b ? blk_queue_discard(b) : true;
 
-	if (can_do && b && !queue_discard_zeroes_data(b) && !discard_zeroes_if_aligned) {
+	if (can_do && b && 1/* !queue_discard_zeroes_data(q) */ && !discard_zeroes_if_aligned) {
 		can_do = false;
 		drbd_info(device, "discard_zeroes_data=0 and discard_zeroes_if_aligned=no: disabling discards\n");
 	}
@@ -2124,7 +2124,13 @@ static void drbd_setup_queue_param(struc
 
 	if (b) {
 		blk_stack_limits(&q->limits, &b->limits, 0);
-		blk_queue_update_readahead(q);
+		if (q->backing_dev_info->ra_pages != b->backing_dev_info->ra_pages) {
+			drbd_info(device,
+				  "Adjusting my ra_pages to backing device's (%lu -> %lu)\n",
+				  q->backing_dev_info->ra_pages,
+				  b->backing_dev_info->ra_pages);
+			q->backing_dev_info->ra_pages = b->backing_dev_info->ra_pages;
+		}
 	}
 	fixup_discard_if_not_supported(q);
 	fixup_write_zeroes(device, q);
@@ -2239,7 +2245,7 @@ static void sanitize_disk_conf(struct dr
 		disk_conf->al_extents = drbd_al_extents_max(nbc);
 
 	if (!blk_queue_discard(q) ||
-	    (!queue_discard_zeroes_data(q) && !disk_conf->discard_zeroes_if_aligned)) {
+	    (1/* !queue_discard_zeroes_data(q) */ && !disk_conf->discard_zeroes_if_aligned)) {
 		if (disk_conf->rs_discard_granularity) {
 			disk_conf->rs_discard_granularity = 0; /* disable feature */
 			drbd_info(device, "rs_discard_granularity feature disabled\n");
@@ -5307,7 +5313,7 @@ static int nla_put_drbd_cfg_context(stru
 				    struct drbd_path *path)
 {
 	struct nlattr *nla;
-	nla = nla_nest_start_noflag(skb, DRBD_NLA_CFG_CONTEXT);
+	nla = nla_nest_start(skb, DRBD_NLA_CFG_CONTEXT);
 	if (!nla)
 		goto nla_put_failure;
 	if (device)
@@ -5566,7 +5572,7 @@ int drbd_adm_dump_connections_done(struc
 static int connection_paths_to_skb(struct sk_buff *skb, struct drbd_connection *connection)
 {
 	struct drbd_path *path;
-	struct nlattr *tla = nla_nest_start_noflag(skb, DRBD_NLA_PATH_PARMS);
+	struct nlattr *tla = nla_nest_start(skb, DRBD_NLA_PATH_PARMS);
 	if (!tla)
 		goto nla_put_failure;
 
--- drbd_bitmap.c
+++ /tmp/cocci-output-3683926-4e2c1e-drbd_bitmap.c
@@ -365,7 +365,8 @@ static struct page **bm_realloc_pages(st
 	new_pages = kzalloc(bytes, GFP_NOIO | __GFP_NOWARN);
 	if (!new_pages) {
 		new_pages = __vmalloc(bytes,
-				GFP_NOIO | __GFP_HIGHMEM | __GFP_ZERO);
+				      GFP_NOIO | __GFP_HIGHMEM | __GFP_ZERO,
+				      PAGE_KERNEL);
 		if (!new_pages)
 			return NULL;
 	}
--- drbd_sender.c
+++ /tmp/cocci-output-3683926-f38eed-drbd_sender.c
@@ -23,7 +23,6 @@
 #include <linux/random.h>
 #include <linux/scatterlist.h>
 #include <linux/overflow.h>
-#include <linux/part_stat.h>
 
 #include "drbd_int.h"
 #include "drbd_protocol.h"
--- drbd_transport_tcp.c
+++ /tmp/cocci-output-3683926-6f78be-drbd_transport_tcp.c
@@ -152,6 +152,33 @@ static struct drbd_path *__drbd_next_pat
 	return drbd_path;
 }
 
+static void dtt_cork(struct socket *socket)
+{
+	int val = 1;
+	(void)kernel_setsockopt(socket, SOL_TCP, TCP_CORK, (char *)&val,
+				sizeof(val));
+}
+static void dtt_uncork(struct socket *socket)
+{
+	int val = 0;
+	(void)kernel_setsockopt(socket, SOL_TCP, TCP_CORK, (char *)&val,
+				sizeof(val));
+}
+
+static void dtt_nodelay(struct socket *socket)
+{
+	int val = 1;
+	(void)kernel_setsockopt(socket, SOL_TCP, TCP_NODELAY, (char *)&val,
+				sizeof(val));
+}
+
+static void dtt_quickack(struct socket *socket)
+{
+	int val = 2;
+	(void)kernel_setsockopt(socket, SOL_TCP, TCP_QUICKACK, (char *)&val,
+				sizeof(val));
+}
+
 static int dtt_init(struct drbd_transport *transport)
 {
 	struct drbd_tcp_transport *tcp_transport =
@@ -1049,8 +1076,8 @@ randomize:
 
 	/* we don't want delays.
 	 * we use tcp_sock_set_cork where appropriate, though */
-	tcp_sock_set_nodelay(dsocket->sk);
-	tcp_sock_set_nodelay(csocket->sk);
+	dtt_nodelay(dsocket);
+	dtt_nodelay(csocket);
 
 	tcp_transport->stream[DATA_STREAM] = dsocket;
 	tcp_transport->stream[CONTROL_STREAM] = csocket;
@@ -1064,7 +1091,11 @@ randomize:
 	dsocket->sk->sk_sndtimeo = timeout;
 	csocket->sk->sk_sndtimeo = timeout;
 
-	sock_set_keepalive(dsocket->sk);
+	{
+		int one = 1;
+		kernel_setsockopt(dsocket, SOL_SOCKET, SO_KEEPALIVE,
+				  (char *)&one, sizeof(one));
+	}
 
 	return 0;
 
@@ -1212,20 +1243,20 @@ static bool dtt_hint(struct drbd_transpo
 
 	switch (hint) {
 	case CORK:
-		tcp_sock_set_cork(socket->sk, true);
+		dtt_cork(socket);
 		break;
 	case UNCORK:
-		tcp_sock_set_cork(socket->sk, false);
+		dtt_uncork(socket);
 		break;
 	case NODELAY:
-		tcp_sock_set_nodelay(socket->sk);
+		dtt_nodelay(socket);
 		break;
 	case NOSPACE:
 		if (socket->sk->sk_socket)
 			set_bit(SOCK_NOSPACE, &socket->sk->sk_socket->flags);
 		break;
 	case QUICKACK:
-		tcp_sock_set_quickack(socket->sk, 2);
+		dtt_quickack(socket);
 		break;
 	default: /* not implemented, but should not trigger error handling */
 		return true;
--- drbd_debugfs.c
+++ /tmp/cocci-output-3683926-100db2-drbd_debugfs.c
@@ -1728,6 +1728,32 @@ static const struct file_operations drbd
 
 static int drbd_compat_show(struct seq_file *m, void *ignored)
 {
+	seq_puts(m, "blk_queue_split__yes_has_two_parameters\n");
+	seq_puts(m, "ib_device__no_has_ops\n");
+	seq_puts(m, "submit_bio__no_present\n");
+	seq_puts(m, "blk_queue_make_request__yes_present\n");
+	seq_puts(m, "genl_policy__yes_in_ops\n");
+	seq_puts(m, "queue_flag_stable_writes__no_present\n");
+	seq_puts(m, "bio_start_io_acct__no_present\n");
+	seq_puts(m, "nla_nest_start_noflag__no_present\n");
+	seq_puts(m, "nla_parse_deprecated__no_present\n");
+	seq_puts(m, "allow_kernel_signal__no_present\n");
+	seq_puts(m, "part_stat_h__no_present\n");
+	seq_puts(m, "__vmalloc__no_has_2_params\n");
+	seq_puts(m, "tcp_sock_set_cork__no_present\n");
+	seq_puts(m, "tcp_sock_set_nodelay__no_present\n");
+	seq_puts(m, "tcp_sock_set_quickack__no_present\n");
+	seq_puts(m, "sock_set_keepalive__no_present\n");
+	seq_puts(m, "submit_bio_noacct__no_present\n");
+	seq_puts(m, "congested_fn__yes_present\n");
+	seq_puts(m, "blk_queue_update_readahead__no_present\n");
+	seq_puts(m, "sendpage_ok__no_present\n");
+	seq_puts(m, "fallthrough__no_present\n");
+	seq_puts(m, "revalidate_disk_size__no_present\n");
+	seq_puts(m, "sched_set_fifo__no_present\n");
+	seq_puts(m, "vermagic_h__yes_can_include\n");
+	seq_puts(m, "nla_strscpy__no_present\n");
+	seq_puts(m, "queue_discard_zeroes_data__no_present\n");
 	return 0;
 }
 
--- drbd-headers/linux/genl_magic_func.h
+++ drbd-headers/linux/genl_magic_func.h
@@ -233,6 +233,7 @@ static const char *CONCAT_(GENL_MAGIC_FAMILY, _genl_cmd_to_str)(__u8 cmd)
 {								\
 	handler							\
 	.cmd = op_name,						\
+	.policy	= CONCAT_(GENL_MAGIC_FAMILY, _tla_nl_policy),	\
 },
 
 #define ZZZ_genl_ops		CONCAT_(GENL_MAGIC_FAMILY, _genl_ops)
@@ -291,7 +292,6 @@ static struct genl_family ZZZ_genl_family __read_mostly = {
 #ifdef COMPAT_HAVE_GENL_FAMILY_PARALLEL_OPS
 	.parallel_ops = true,
 #endif
-	.policy = CONCAT_(GENL_MAGIC_FAMILY, _tla_nl_policy),
 };
 
 /*
